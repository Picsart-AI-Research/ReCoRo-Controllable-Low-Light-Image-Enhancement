from pathlib import Path
import random
from collections import OrderedDict
from itertools import chain

import torch
import torch.nn.functional as F

from .generators import get_generator
from .discriminators import get_discriminator_A, get_discriminator_P
from .losses import GANLoss, PerceptualLoss, SSIMLoss
from .utils import init_net, print_network
from data.transform import SyncRandomCrop

def get_model(cfg, device, is_train=True):
    if cfg.model.type == "EnlightenGAN":
        return EnlightenGAN(cfg=cfg.model, device=device, is_train=is_train)
    elif cfg.model.type == "ReCoRoGAN":
        return ReCoRoGAN(cfg=cfg.model, device=device, is_train=is_train)
    else:
        raise "Unknown model"

class EnlightenGAN():
    def name(self):
        return "EnlightenGAN"

    def __init__(self, cfg=None, device="cpu", is_train=True):
        self.device = device
        self.cfg = cfg

        self.netG = get_generator(cfg, device)
        self.netD_A = get_discriminator_A(cfg, device)
        self.netD_P = get_discriminator_P(cfg, device)
        
        self.networks = {
            "netG": self.netG,
            "netD_A": self.netD_A,
            "netD_P": self.netD_P,
        }

        if is_train:
            for name, net in self.networks.items():
                print(f"<============|{name}|============>")
                init_net(net)
                net.train()
                print_network(net)

            self.criterionGAN = GANLoss(cfg).to(self.device)
            self.perc_criterion = PerceptualLoss(cfg).to(self.device)

            self.optimizer_G = torch.optim.Adam(self.netG.parameters(), lr=cfg.optim.lr, betas=(cfg.optim.beta1, 0.999))
            self.optimizer_D = torch.optim.Adam(chain(self.netD_A.parameters(), self.netD_P.parameters()), lr=cfg.optim.lr, betas=(cfg.optim.beta1, 0.999))
            self.optimizers = {
                "G": self.optimizer_G,
                "D": self.optimizer_D,
            }

            scheduler_G = torch.optim.lr_scheduler.LinearLR(
                self.optimizer_G, 
                start_factor=1.0, 
                end_factor=0.0,
                total_iters=self.cfg.optim.decay,
                )

            scheduler_D = torch.optim.lr_scheduler.LinearLR(
                self.optimizer_D, 
                start_factor=1.0, 
                end_factor=0.0,
                total_iters=self.cfg.optim.decay,
                )

            self.schedulers = {
                "G": scheduler_G,
                "D": scheduler_D,
            }

            self.random_crop = SyncRandomCrop(size=self.cfg.patches.size)
        
        else:
            for name, net in self.networks.items():
                continue
                net.eval()

    def process_input(self, input):
        """Unpack input data from the dataloader and perform necessary pre-processing steps.
        Parameters:
            input (dict): include the data itself and its metadata information.
        """
        real_A = input["image_A"].to(self.device)
        real_A_gray = input["A_gray"].to(self.device)
        real_B = input["image_B"].to(self.device)
        return real_A, real_A_gray, real_B

    def forward(self, real_A, real_A_gray):
        fake_B, latent = self.netG(real_A, real_A_gray)
        return fake_B, latent
    
    @torch.no_grad()
    def predict(self, input):
        img = input["image_A"].to(self.device)
        img_gray = input["A_gray"].to(self.device)
        fake_B, latent = self.netG(img, img_gray)
        return {
                "fake_B": fake_B.cpu().detach(), 
                "latent": latent.cpu().detach(),
                } 

    def forward_patches(self, *images):
        patches = []
        for _ in range(self.cfg.patches.number):
            patch = self.random_crop(images)
            patches.append(patch)
        return list(zip(*patches))


    def backward_D_basic(self, netD, real, fake, use_ragan=False):
        """Calculate GAN loss for the discriminator
        Parameters:
            netD (network)      -- the discriminator D
            real (tensor array) -- real images
            fake (tensor array) -- images generated by a generator
        Return the discriminator loss.
        We also call loss_D.backward() to calculate the gradients.
        """

        pred_real = netD(real)
        pred_fake = netD(fake.detach())
        if use_ragan:
            loss_D_real = self.criterionGAN(pred_real - torch.mean(pred_fake), True)
            loss_D_fake = self.criterionGAN(pred_fake - torch.mean(pred_real), False)
        else:
            loss_D_real = self.criterionGAN(pred_real, True)
            loss_D_fake = self.criterionGAN(pred_fake, False)

        # Combined loss
        loss_D = (loss_D_real + loss_D_fake) * 0.5
        return loss_D

    def backward_D_A(self, real_B, fake_B):
        """Calculate GAN loss for discriminator D_A"""
        loss_D_A = self.backward_D_basic(self.netD_A, real_B, fake_B, use_ragan=True)
        loss_D_A.backward()
        return loss_D_A


    def backward_D_P(self, real_B_patches, fake_B_patches):
        loss_D_P = None
        for real_B_patch, fake_B_patch in zip(real_B_patches, fake_B_patches):
            if loss_D_P is None:
                loss_D_P = self.backward_D_basic(self.netD_P, real_B_patch, fake_B_patch, False)
            else:
                loss_D_P += self.backward_D_basic(self.netD_P, real_B_patch, fake_B_patch, False)
        loss_D_P = loss_D_P / self.cfg.patches.number
        loss_D_P.backward()
        return loss_D_P

    def backward_G(self, real_A, real_B, fake_B, real_A_patches, fake_B_patches):
        """Calculate the loss for generator G"""
        pred_fake = self.netD_A(fake_B)
        pred_real = self.netD_A(real_B)

        loss_G_A_real = self.criterionGAN(pred_real - torch.mean(pred_fake), False)
        loss_G_A_fake = self.criterionGAN(pred_fake - torch.mean(pred_real), True)
        loss_G_A = (loss_G_A_real + loss_G_A_fake) * 0.5

        loss_G_A_patch = None
        for fake_B_patch in fake_B_patches:
            pred_fake_B_patch = self.netD_P.forward(fake_B_patch)
            if loss_G_A_patch is None:
                loss_G_A_patch = self.criterionGAN(pred_fake_B_patch, True)
            else:
                loss_G_A_patch += self.criterionGAN(pred_fake_B_patch, True)
        loss_G_A += loss_G_A_patch / self.cfg.patches.number

        perc_loss = self.perc_criterion(fake_B, real_A)
        perc_patch_loss = None
        for fake_B_patch, real_A_patch in zip(fake_B_patches, real_A_patches):
            if perc_patch_loss is None:
                perc_patch_loss = self.perc_criterion(fake_B_patch, real_A_patch)
            else:
                perc_patch_loss += self.perc_criterion(fake_B_patch, real_A_patch)
        perc_loss += perc_patch_loss / self.cfg.patches.number

        loss_G = loss_G_A + perc_loss
        loss_G.backward()
        return loss_G, loss_G_A, perc_loss

    def step(self, input, return_images=True):
        """Calculate losses, gradients, and update network weights; called in every training iteration"""
        
        real_A, real_A_gray, real_B = self.process_input(input)
        # forward
        fake_B, latent = self.forward(real_A, real_A_gray)
        real_A_patches, real_B_patches, fake_B_patches = self.forward_patches(real_A, real_B, fake_B)
        # G
        self.optimizer_G.zero_grad() 
        loss_G, loss_G_A, perc_loss = self.backward_G(real_A, real_B, fake_B, real_A_patches, fake_B_patches)
        self.optimizer_G.step()

        # D_A and D_P
        self.optimizer_D.zero_grad()
        loss_D_A = self.backward_D_A(real_B, fake_B)      
        loss_D_P = self.backward_D_P(real_B_patches, fake_B_patches)
        self.optimizer_D.step()


        losses = {
            "loss_G": loss_G.data.item(), 
            "loss_G_A": loss_G_A.data.item(), 
            "perc_loss": perc_loss.data.item(),
            "loss_D_A": loss_D_A.data.item(),
            "loss_D_P": loss_D_P.data.item(),
        }
        if return_images:
            images = {
                "fake_B": fake_B.cpu().detach(), 
                "latent": latent.cpu().detach(),
                "real_A_patches": [patch.cpu().detach() for patch in real_A_patches], 
                "real_B_patches": [patch.cpu().detach() for patch in real_B_patches], 
                "fake_B_patches": [patch.cpu().detach() for patch in fake_B_patches],
            }
        else:
            images = None
        
        return losses, images

    def update_learning_rate(self, epoch):
        for scheduler_name, scheduler in self.schedulers.items():
            if epoch > self.cfg.optim.decay_start:
                scheduler.step()
                print(f"Updateing lr of {scheduler_name}, {scheduler.get_last_lr()} -> {scheduler.get_lr()}")
            

    def set_requires_grad(self, nets, requires_grad=False):
        """Set requies_grad=Fasle for all the networks to avoid unnecessary computations
        Parameters:
            nets (network list)   -- a list of networks
            requires_grad (bool)  -- whether the networks require gradients or not
        """
        if not isinstance(nets, list):
            nets = [nets]
        for net in nets:
            if net is not None:
                for param in net.parameters():
                    param.requires_grad = requires_grad

    def save(self, epoch, label=""):
        for name, net in self.networks.items():
            save_filename = f"{epoch}_{label}net_{name}.pth"
            last_save_filename = f"last_{label}net_{name}.pth"
            checkpoints = Path("./checkpoints")
            checkpoints.mkdir(parents=True, exist_ok=True)

            torch.save(net.cpu().state_dict(), checkpoints / save_filename)
            torch.save(net.cpu().state_dict(), checkpoints / last_save_filename)
            net.to(self.device)


    def load(self, checkpoints, epoch, label=""):
        for name, net in self.networks.items():
            save_filename = f"{epoch}_{label}net_{name}.pth"
            print(save_filename)
            net.load_state_dict(torch.load(checkpoints / save_filename))

        bn_layers = []
        for layer in self.netG.module.modules():
            if isinstance(layer, torch.nn.modules.batchnorm.BatchNorm2d):
                bn_layers.append(layer)
        for layer in bn_layers:
            if torch.isinf(layer.running_var.mean()):
                layer.running_var = torch.ones_like(layer.running_var)




class ReCoRoGAN(EnlightenGAN):
    def __init__(self, cfg=None, device="cpu", is_train=True):
        super().__init__(cfg=cfg, device=device, is_train=is_train)
        if is_train:
            self.alpha_criterion = torch.nn.MSELoss()
            self.bg_criterion = torch.nn.MSELoss()
            self.ssim_criterion = SSIMLoss(data_range=1, device=device)
    
    def name(self):
        return "ReCoRoGAN"
    
    # @timeit("process_input")
    def process_input(self, input, prefix="ds_A_"):
        """Unpack input data from the dataloader and perform necessary pre-processing steps.
        Parameters:
            input (dict): include the data itself and its metadata information.
        """
        real_A = input[prefix + "image_A"].to(self.device)
        real_B = input[prefix + "image_B"].to(self.device)
        alpha = input[prefix + "alpha"].to(real_A.dtype).to(self.device).view(-1, 1, 1, 1)
        gt_mask = input[prefix + "gt_mask"].to(self.device)
        input_mask = input[prefix + "input_mask"].to(self.device)
        return real_A, gt_mask, input_mask, alpha, real_B

    # @timeit("forward")
    def forward(self, real_A, alpha, mask):
        fake_B, latent= self.netG(real_A, alpha*mask)
        return fake_B, latent

    @torch.no_grad()
    def predict(self, input):
        real_A, gt_mask, input_mask, alpha, real_B = self.process_input(input, prefix="")
        fake_B, latent = self.forward(real_A, alpha, input_mask)
        prediction = {
                "fake_B": fake_B.cpu().detach(), 
                "latent": latent.cpu().detach(), 
                }
        return prediction

    def backward_D_basic(self, netD, real, fake, mask, alpha, use_ragan=False):
        """Calculate GAN loss for the discriminator
        Parameters:
            netD (network)      -- the discriminator D
            real (tensor array) -- real images
            fake (tensor array) -- images generated by a generator
        Return the discriminator loss.
        We also call loss_D.backward() to calculate the gradients.
        """

        pred_real, pred_real_ratio = netD(real, mask)
        pred_fake, pred_fake_ratio = netD(fake.detach(), mask * alpha)
        if use_ragan:
            loss_D_real = self.criterionGAN(pred_real - torch.mean(pred_fake), True)
            loss_D_fake = self.criterionGAN(pred_fake - torch.mean(pred_real), False)
        else:
            loss_D_real = self.criterionGAN(pred_real, True)
            loss_D_fake = self.criterionGAN(pred_fake, False)
                
        loss_ratio = F.mse_loss(mask, pred_real_ratio) + F.mse_loss(mask * alpha, pred_fake_ratio)
        # Combined loss
        loss_D = (loss_D_real + loss_D_fake) * 0.5
        return loss_D, loss_ratio

    def backward_D_A(self, real_B, fake_B, mask, alpha=1.0):
        """Calculate GAN loss for discriminator D_A"""
        loss_D_A, loss_ratio = self.backward_D_basic(self.netD_A, real_B, fake_B, mask, alpha, use_ragan=True)
        loss_ratio = 30.0 * loss_ratio
        (loss_D_A + loss_ratio).backward()
        return loss_D_A, loss_ratio


    def backward_D_P(self, real_B_patches, fake_B_patches, mask_patches, alpha=1.0):
        loss_D_P = None
        loss_ratio = None
        for real_B_patch, fake_B_patch, mask_patch in zip(real_B_patches, fake_B_patches, mask_patches):
            if loss_D_P is None:
                loss_D_P, loss_ratio = self.backward_D_basic(self.netD_P, real_B_patch, fake_B_patch, mask_patch, alpha, False)
            else:
                loss_D_P_, loss_ratio_ = self.backward_D_basic(self.netD_P, real_B_patch, fake_B_patch, mask_patch, alpha, False)
                loss_D_P += loss_D_P_
                loss_ratio += loss_ratio_
        loss_D_P = loss_D_P / self.cfg.patches.number
        loss_ratio = 20.0 * loss_ratio / self.cfg.patches.number
        (loss_D_P + loss_ratio).backward()
        return loss_D_P, loss_ratio


    # @timeit("backward_G_alpha")
    def backward_G_alpha(self, real_A, real_B, fake_B, latent, alpha, gt_mask):
        """Calculate the loss for generator G"""
        alpha_blend = (1.0 - alpha * gt_mask) * real_A + alpha * gt_mask * real_B
        alpha_loss = 2.0*self.alpha_criterion(fake_B, alpha_blend)
        pred_fake, pred_fake_ratio = self.netD_A(fake_B, gt_mask) 
        ssim_loss = torch.mean(self.ssim_criterion(fake_B, alpha_blend))

        gt_mask = F.interpolate(gt_mask, scale_factor=1/8.0, mode='nearest')
        gt_mask = F.interpolate(gt_mask, scale_factor=8.0, mode='nearest')
        mask_loss = torch.mean(torch.abs(fake_B - real_A) * (1 - gt_mask)) * 10

        latent_loss = 30.0 * self.alpha_criterion((1.0 - gt_mask) * latent, torch.zeros_like(latent))

        loss_ratio = 30.0*F.mse_loss(pred_fake_ratio, gt_mask)

        loss = alpha_loss + mask_loss + loss_ratio + latent_loss + ssim_loss
        loss.backward()
        return alpha_loss, mask_loss, loss_ratio, latent_loss, ssim_loss, alpha_blend, pred_fake

    def backward_G(self, real_A, real_B, fake_B, real_A_patches, fake_B_patches, alpha, gt_mask, gt_mask_patches):
        """Calculate the loss for generator G"""
        pred_fake, pred_fake_ratio = self.netD_A(fake_B, gt_mask) 
        pred_real, pred_real_ratio = self.netD_A(real_B, gt_mask)
        loss_G_A_real = self.criterionGAN(pred_real - torch.mean(pred_fake), False)
        loss_G_A_fake = self.criterionGAN(pred_fake - torch.mean(pred_real), True)
        loss_G_A = (loss_G_A_real + loss_G_A_fake) * 0.5

        loss_ratio = F.mse_loss(pred_fake_ratio, gt_mask*alpha)
        loss_G_A_patch = 0
        loss_ratio_patch = 0
        for fake_B_patch, gt_mask_patche in zip(fake_B_patches, gt_mask_patches):
            pred_fake_B_patch, pred_ratio_patch = self.netD_P.forward(fake_B_patch, gt_mask_patche)
            if loss_G_A_patch is None:
                loss_G_A_patch = self.criterionGAN(pred_fake_B_patch, True)
                loss_ratio_patch = F.mse_loss(pred_ratio_patch, gt_mask_patche*alpha)
            else:
                loss_G_A_patch += -torch.mean(pred_fake_B_patch)
                loss_ratio_patch += F.mse_loss(pred_ratio_patch, gt_mask_patche*alpha)

        loss_G_A_patch = loss_G_A_patch / self.cfg.patches.number
        loss_ratio += loss_ratio_patch / self.cfg.patches.number
        perc_loss = self.perc_criterion(fake_B, real_A)
        perc_patch_loss = None
        for fake_B_patch, real_A_patch in zip(fake_B_patches, real_A_patches):
            if perc_patch_loss is None:
                perc_patch_loss = self.perc_criterion(fake_B_patch, real_A_patch)
            else:
                perc_patch_loss += self.perc_criterion(fake_B_patch, real_A_patch)
        perc_loss += perc_patch_loss / self.cfg.patches.number

        loss_G = loss_G_A + loss_G_A_patch + perc_loss + loss_ratio
        loss_G.backward()
        return loss_G, loss_G_A, loss_G_A_patch, perc_loss, loss_ratio, pred_fake, pred_real

    # @timeit("step_unpaired")
    def step_unpaired(self, input, return_images=True):
        """Calculate losses, gradients, and update network weights; called in every training iteration"""
        
        real_A, gt_mask, input_mask, alpha, real_B = self.process_input(input)
        # forward
        fake_B, latent = self.forward(real_A, alpha, input_mask)
        real_A_patches, real_B_patches, fake_B_patches, gt_mask_patches, input_mask_patches = self.forward_patches(real_A, real_B, fake_B, gt_mask, input_mask)
        # G
        self.optimizer_G.zero_grad() 
        loss_G, loss_G_A, loss_G_A_patch, perc_loss, loss_ratio, pred_fake, pred_real = self.backward_G(real_A, real_B, fake_B, real_A_patches, fake_B_patches, alpha, gt_mask, gt_mask_patches)
        self.optimizer_G.step()

        # D_A and D_P
        self.optimizer_D.zero_grad()
        loss_D_A, loss_ratio_D_A = self.backward_D_A(real_B, fake_B, gt_mask, alpha)      
        # loss_D_P, loss_ratio_D_P = self.backward_D_P(real_B_patches, fake_B_patches, gt_mask_patches, alpha)
        loss_D_P, loss_ratio_D_P = loss_D_A, loss_ratio_D_A
        self.optimizer_D.step()

        losses = {
            "loss_G": loss_G.data.item(), 
            "loss_G_A": loss_G_A.data.item(), 
            "loss_G_A_patch": loss_G_A_patch.data.item(), 
            "perc_loss": perc_loss.data.item(),
            "loss_ratio": loss_ratio.data.item(),
            "loss_D_A": loss_D_A.data.item(),
            "loss_ratio_D_A": loss_ratio_D_A.data.item(),
            "loss_D_P": loss_D_P.data.item(),
            "loss_ratio_D_P": loss_ratio_D_P.data.item(),
        }

        if return_images:
            images = {
                    "fake_B": fake_B.cpu().detach(), 
                    "latent": latent.cpu().detach(), 
                    "pred_fake": pred_fake.cpu().detach(), 
                    "pred_real": pred_real.cpu().detach(), 
                    "real_A_patches": [patch.cpu().detach() for patch in real_A_patches], 
                    "real_B_patches": [patch.cpu().detach() for patch in real_B_patches], 
                    "fake_B_patches": [patch.cpu().detach() for patch in fake_B_patches],
                }
        else:
            images = None
        
        return losses, images
            


    # @timeit("step_paired")
    def step_paired(self, input, return_images=True):
        """Calculate losses, gradients, and update network weights; called in every training iteration"""

        real_A, gt_mask, input_mask, alpha, real_B = self.process_input(input, prefix="ds_B_")
        # forward
        fake_B, latent = self.forward(real_A, alpha, input_mask)
        real_A_patches, real_B_patches, fake_B_patches, gt_mask_patches, input_mask_patches = self.forward_patches(real_A, real_B, fake_B, gt_mask, input_mask)

        # G
        self.optimizer_G.zero_grad() 
        alpha_loss, mask_loss, loss_ratio, latent_loss, ssim_loss, alpha_blend, pred_fake = self.backward_G_alpha(real_A, real_B, fake_B, latent, alpha, gt_mask)
        self.optimizer_G.step()

        self.optimizer_D.zero_grad()
        loss_D_A, loss_ratio_D_A = self.backward_D_A(real_B, fake_B, gt_mask, alpha)      
        # loss_D_P, loss_ratio_D_P = self.backward_D_P(real_B_patches, fake_B_patches, gt_mask_patches, alpha)
        loss_D_P, loss_ratio_D_P = loss_D_A, loss_ratio_D_A
        self.optimizer_D.step()

        losses = {
            "alpha_loss": alpha_loss.data.item(), 
            "mask_loss": mask_loss.data.item(), 
            "loss_ratio": loss_ratio.data.item(), 
            "latent_loss": latent_loss.data.item(), 
            "ssim_loss": ssim_loss.data.item(), 
            "loss_D_A": loss_D_A.data.item(),
            "loss_ratio_D_A": loss_ratio_D_A.data.item(),
            "loss_D_P": loss_D_P.data.item(),
            "loss_ratio_D_P": loss_ratio_D_P.data.item(),
        }

        if return_images:
            images = {
                "fake_B": fake_B.cpu().detach(), 
                "latent": latent.cpu().detach(), 
                "pred_fake": pred_fake.cpu().detach(), 
                "alpha_blend": alpha_blend.cpu().detach(),
            }

        else:
            images = None

        return losses, images
            
        

    def step(self, input, return_images, epoch, batch_idx):
        """Calculate losses, gradients, and update network weights; called in every training iteration"""
        
        unpaired_losses, unpaired_images = self.step_unpaired(input, return_images)
        if (epoch % self.cfg.save_freq == 0) and batch_idx == 0:
            self.save(epoch=epoch, label="up_")
        paired_losses, paired_images = self.step_paired(input, return_images)
        return (unpaired_losses, paired_losses), (unpaired_images, paired_images)